{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "09d2bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libaries etc\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6aad5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data and splitting\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "63dd9254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the shape\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ec12415a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 138,\n",
       "        170, 253, 201, 244, 212, 222, 138,  86,  22,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  95, 253, 252,\n",
       "        252, 252, 252, 253, 252, 252, 252, 252, 245,  80,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  68, 246, 205,  69,\n",
       "         69,  69,  69,  69,  69,  69,  69, 205, 253, 240,  50,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 187, 252, 218,  34,\n",
       "          0,   0,   0,   0,   0,   0,   0, 116, 253, 252,  69,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 116, 248, 252, 253,  92,\n",
       "          0,   0,   0,   0,   0,   0,  95, 230, 253, 157,   6,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 116, 249, 253, 189,  42,\n",
       "          0,   0,   0,   0,  36, 170, 253, 243, 158,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 252, 245, 140,\n",
       "         34,   0,   0,  57, 219, 252, 235,  60,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 205, 253, 252,\n",
       "        234, 184, 184, 253, 240, 100,  44,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 161, 219,\n",
       "        252, 252, 252, 234,  37,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 203,\n",
       "        252, 252, 252, 251, 135,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  76, 255, 253,\n",
       "        205, 168, 220, 255, 253, 137,   5,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 114, 252, 249, 132,\n",
       "         25,   0,   0, 180, 252, 252,  45,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  51, 220, 252, 199,   0,\n",
       "          0,   0,   0,  38, 186, 252, 154,   7,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,  21,   0,\n",
       "          0,   0,   0,   0,  67, 252, 252,  22,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 200,   0,   0,\n",
       "          0,   0,   0,   0,  47, 252, 252,  22,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 185, 253, 201,   0,   0,\n",
       "          0,   0,   0,   3, 118, 253, 245,  21,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 163, 252, 252,   0,   0,\n",
       "          0,   0,   0,  97, 252, 252,  87,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  51, 240, 252, 123,  70,\n",
       "         70, 112, 184, 222, 252, 170,  13,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 165, 252, 253, 252,\n",
       "        252, 252, 252, 245, 139,  13,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  75, 253, 252,\n",
       "        221, 137, 137,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputting array\n",
    "x_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "80338a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "97476572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8e5a1c5050>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[333], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "25a83940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8e310fecd0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[123], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "90241f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8e31aeba90>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[576], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e41a7a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) train samples\n",
      "(10000, 28, 28) test samples\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, 'train samples')\n",
    "print(x_test.shape, 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "12945ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting images and coverting them to vectors\n",
    "x_train = x_train.reshape(len(x_train), 28*28)\n",
    "x_test = x_test.reshape(len(x_test), 28*28)\n",
    "\n",
    "# Keras with floats\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1f0109f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector to binary\n",
    "num_classes = 10 \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train[333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "840010d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with two hidden layers. Each connected and have a dropout of .2\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(784,)))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4e6b652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 59,210\n",
      "Trainable params: 59,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8c57e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .001\n",
    "model_1.compile(loss='categorical_crossentropy',\n",
    "                optimizer=RMSprop(lr=learning_rate),\n",
    "                metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "be608b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.4925 - accuracy: 0.8500 - val_loss: 0.1958 - val_accuracy: 0.9419\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2389 - accuracy: 0.9298 - val_loss: 0.1545 - val_accuracy: 0.9522\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1899 - accuracy: 0.9441 - val_loss: 0.1301 - val_accuracy: 0.9619\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1629 - accuracy: 0.9525 - val_loss: 0.1133 - val_accuracy: 0.9659\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1469 - accuracy: 0.9572 - val_loss: 0.1125 - val_accuracy: 0.9667\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1357 - accuracy: 0.9607 - val_loss: 0.1046 - val_accuracy: 0.9684\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1231 - accuracy: 0.9635 - val_loss: 0.1001 - val_accuracy: 0.9711\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1182 - accuracy: 0.9649 - val_loss: 0.1076 - val_accuracy: 0.9704\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1100 - accuracy: 0.9674 - val_loss: 0.0956 - val_accuracy: 0.9725\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1053 - accuracy: 0.9691 - val_loss: 0.0941 - val_accuracy: 0.9722\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1013 - accuracy: 0.9698 - val_loss: 0.1033 - val_accuracy: 0.9715\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0982 - accuracy: 0.9714 - val_loss: 0.0921 - val_accuracy: 0.9734\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0962 - accuracy: 0.9718 - val_loss: 0.0956 - val_accuracy: 0.9739\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0923 - accuracy: 0.9731 - val_loss: 0.0952 - val_accuracy: 0.9742\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0901 - accuracy: 0.9733 - val_loss: 0.0975 - val_accuracy: 0.9736\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0866 - accuracy: 0.9748 - val_loss: 0.0950 - val_accuracy: 0.9754\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0836 - accuracy: 0.9751 - val_loss: 0.0963 - val_accuracy: 0.9744\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0866 - accuracy: 0.9749 - val_loss: 0.0901 - val_accuracy: 0.9764\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0832 - accuracy: 0.9751 - val_loss: 0.0965 - val_accuracy: 0.9750\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0819 - accuracy: 0.9759 - val_loss: 0.0952 - val_accuracy: 0.9760\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.0799 - accuracy: 0.9774 - val_loss: 0.0955 - val_accuracy: 0.9754\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0780 - accuracy: 0.9769 - val_loss: 0.0987 - val_accuracy: 0.9754\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0779 - accuracy: 0.9775 - val_loss: 0.1030 - val_accuracy: 0.9765\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0761 - accuracy: 0.9779 - val_loss: 0.1033 - val_accuracy: 0.9748\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0776 - accuracy: 0.9778 - val_loss: 0.1061 - val_accuracy: 0.9759\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0744 - accuracy: 0.9783 - val_loss: 0.0999 - val_accuracy: 0.9755\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0754 - accuracy: 0.9789 - val_loss: 0.0999 - val_accuracy: 0.9756\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0767 - accuracy: 0.9783 - val_loss: 0.0973 - val_accuracy: 0.9760\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0752 - accuracy: 0.9788 - val_loss: 0.1034 - val_accuracy: 0.9748\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0763 - accuracy: 0.9786 - val_loss: 0.0982 - val_accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "# Fitting the data\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "history = model_1.fit(x_train, y_train, batch_size=batch_size,\n",
    "                     epochs=epochs, verbose=1,\n",
    "                     validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45b4e627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.027123487261814686\n",
      "Test accuracy: 0.9927499890327454\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(x_train, y_train, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c1b6e22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(400, activation='relu', input_shape=(784,)))\n",
    "model_2.add(Dropout(0.4))\n",
    "model_2.add(Dense(300, activation='relu', input_shape=(784,)))\n",
    "model_2.add(Dropout(0.4))\n",
    "model_2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5e6a3260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.3241 - accuracy: 0.9003 - val_loss: 0.1267 - val_accuracy: 0.9593\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.1483 - accuracy: 0.9552 - val_loss: 0.0970 - val_accuracy: 0.9719\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.1193 - accuracy: 0.9649 - val_loss: 0.0828 - val_accuracy: 0.9762\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.1010 - accuracy: 0.9711 - val_loss: 0.0846 - val_accuracy: 0.9757\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0929 - accuracy: 0.9728 - val_loss: 0.0817 - val_accuracy: 0.9778\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0836 - accuracy: 0.9770 - val_loss: 0.0774 - val_accuracy: 0.9796\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0772 - accuracy: 0.9779 - val_loss: 0.0756 - val_accuracy: 0.9808\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0746 - accuracy: 0.9793 - val_loss: 0.0789 - val_accuracy: 0.9810\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0690 - accuracy: 0.9805 - val_loss: 0.0843 - val_accuracy: 0.9788\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0673 - accuracy: 0.9816 - val_loss: 0.0796 - val_accuracy: 0.9817\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0673 - accuracy: 0.9817 - val_loss: 0.0881 - val_accuracy: 0.9817\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0578 - accuracy: 0.9845 - val_loss: 0.0873 - val_accuracy: 0.9821\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0588 - accuracy: 0.9844 - val_loss: 0.0974 - val_accuracy: 0.9803\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0560 - accuracy: 0.9851 - val_loss: 0.0923 - val_accuracy: 0.9828\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0565 - accuracy: 0.9854 - val_loss: 0.0998 - val_accuracy: 0.9804\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0561 - accuracy: 0.9852 - val_loss: 0.1032 - val_accuracy: 0.9815\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0527 - accuracy: 0.9860 - val_loss: 0.1000 - val_accuracy: 0.9821\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0548 - accuracy: 0.9856 - val_loss: 0.1034 - val_accuracy: 0.9817\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0511 - accuracy: 0.9869 - val_loss: 0.1080 - val_accuracy: 0.9819\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.0493 - accuracy: 0.9873 - val_loss: 0.1180 - val_accuracy: 0.9823\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0472 - accuracy: 0.9876 - val_loss: 0.1055 - val_accuracy: 0.9817\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 0.1126 - val_accuracy: 0.9834\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0457 - accuracy: 0.9881 - val_loss: 0.1003 - val_accuracy: 0.9832\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0506 - accuracy: 0.9879 - val_loss: 0.1110 - val_accuracy: 0.9817\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 0.1015 - val_accuracy: 0.9834\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.1115 - val_accuracy: 0.9830\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0488 - accuracy: 0.9884 - val_loss: 0.1105 - val_accuracy: 0.9836\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0469 - accuracy: 0.9886 - val_loss: 0.1180 - val_accuracy: 0.9829\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.1173 - val_accuracy: 0.9829\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 0.1147 - val_accuracy: 0.9842\n",
      "\n",
      "Test loos: 0.11472138528971706\n",
      "Test accuracy: 0.9842000007629395\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "ephochs = 20\n",
    "learning_rate = .001\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=RMSprop(lr=learning_rate),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model_2.fit(x_train, y_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     verbose=1,\n",
    "                     validation_data=(x_test, y_test))\n",
    "\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('')\n",
    "print('Test loos:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c9fb5d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 400)               314000    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 437,310\n",
      "Trainable params: 437,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#How they compare\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(400, activation='relu', input_shape=(784,)))\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(Dense(300, activation='relu', input_shape=(784,)))\n",
    "model_3.add(Dropout(0.1))\n",
    "model_3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fc2a5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0283 - accuracy: 0.9923 - val_loss: 0.1133 - val_accuracy: 0.9841\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 0.1164 - val_accuracy: 0.9841\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0234 - accuracy: 0.9937 - val_loss: 0.1183 - val_accuracy: 0.9842\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0223 - accuracy: 0.9941 - val_loss: 0.1183 - val_accuracy: 0.9841\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.1201 - val_accuracy: 0.9837\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.1201 - val_accuracy: 0.9840\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.1199 - val_accuracy: 0.9844\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.1220 - val_accuracy: 0.9846\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.1240 - val_accuracy: 0.9848\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.1221 - val_accuracy: 0.9853\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.1237 - val_accuracy: 0.9845\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.1300 - val_accuracy: 0.9842\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 0.1268 - val_accuracy: 0.9848\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.1314 - val_accuracy: 0.9842\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 0.1296 - val_accuracy: 0.9844\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.1264 - val_accuracy: 0.9847\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.1266 - val_accuracy: 0.9840\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0195 - accuracy: 0.9956 - val_loss: 0.1293 - val_accuracy: 0.9848\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.1293 - val_accuracy: 0.9846\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.1317 - val_accuracy: 0.9847\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.1327 - val_accuracy: 0.9850\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.1348 - val_accuracy: 0.9845\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.1336 - val_accuracy: 0.9847\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0186 - accuracy: 0.9960 - val_loss: 0.1370 - val_accuracy: 0.9843\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.0186 - accuracy: 0.9961 - val_loss: 0.1374 - val_accuracy: 0.9848\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.1390 - val_accuracy: 0.9845\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0160 - accuracy: 0.9960 - val_loss: 0.1398 - val_accuracy: 0.9843\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.1359 - val_accuracy: 0.9845\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.1366 - val_accuracy: 0.9846\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.1399 - val_accuracy: 0.9844\n",
      "\n",
      "Test loos: 0.1399073843725758\n",
      "Test accuracy: 0.9843999743461609\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "ephochs = 35\n",
    "learning_rate = .0001\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "                optimizer=RMSprop(lr= .0001),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = model_2.fit(x_train, y_train,\n",
    "                     batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     verbose=1,\n",
    "                     validation_data=(x_test, y_test))\n",
    "\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('')\n",
    "print('Test loos:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f66c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
